import{_ as s,c as a,o as l,af as t}from"./chunks/framework.Cm3tdt7z.js";const g=JSON.parse('{"title":"性能优化指南","description":"","frontmatter":{},"headers":[],"relativePath":"更多/Optimize.md","filePath":"更多/Optimize.md"}'),e={name:"更多/Optimize.md"};function n(h,i,r,o,k,p){return l(),a("div",null,[...i[0]||(i[0]=[t(`<h1 id="性能优化指南" tabindex="-1">性能优化指南 <a class="header-anchor" href="#性能优化指南" aria-label="Permalink to “性能优化指南”">​</a></h1><blockquote><p>本指南提供在本地或云服务器运行 <strong>Webis</strong> 时的性能优化技巧。<br> 由于 Webis 基于 vLLM 和大语言模型，<strong>GPU 显存</strong>和 <strong>CPU 吞吐量</strong> 对性能影响很大。</p></blockquote><h2 id="硬件推荐" tabindex="-1">硬件推荐 <a class="header-anchor" href="#硬件推荐" aria-label="Permalink to “硬件推荐”">​</a></h2><ul><li><strong>GPU</strong>：支持 CUDA 的 NVIDIA GPU <ul><li>推荐：≥ 8GB 显存</li><li>最低：6GB 显存（需降低 <code>--memory-limit</code> 和精度）</li></ul></li><li><strong>CPU</strong>：≥ 4 个物理核心</li><li><strong>内存</strong>：≥ 16GB</li><li><strong>硬盘</strong>：SSD（加快模型加载速度）</li></ul><h2 id="gpu-显存优化" tabindex="-1">GPU 显存优化 <a class="header-anchor" href="#gpu-显存优化" aria-label="Permalink to “GPU 显存优化”">​</a></h2><ol><li><strong>调整显存利用率</strong><ul><li>默认 vLLM 使用 90% 可用显存</li><li>显存不足时可降低：</li></ul></li></ol><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> scripts/start_model_server.py</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --memory-limit</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.6</span></span></code></pre></div><ol start="2"><li><p><strong>使用低精度</strong></p><ul><li><code>float16</code>：显著减少显存占用，精度损失较小</li><li><code>int8</code> 量化：进一步减少显存，但可能影响效果</li></ul><p>示例（在 <code>start_model_server.py</code> 中修改模型加载）：</p></li></ol><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LLM(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model_path,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    tensor_parallel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    gpu_memory_utilization</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gpu_memory_utilization,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    trust_remote_code</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;float16&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><ol start="3"><li><strong>释放显存后再启动</strong></li></ol><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nvidia-smi</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">kill</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -9</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">PI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">D</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span></span></code></pre></div><h2 id="cpu-与并发优化" tabindex="-1">CPU 与并发优化 <a class="header-anchor" href="#cpu-与并发优化" aria-label="Permalink to “CPU 与并发优化”">​</a></h2><ol><li><strong>提升并发请求数</strong></li></ol><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">uvicorn</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> scripts.start_model_server:app</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --host</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0.0.0</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --port</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8000</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --workers</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span></span></code></pre></div><ol start="2"><li><strong>请求批处理</strong><ul><li>vLLM 支持批量处理多条 prompt</li><li>建议合并小请求为一次 API 调用</li></ul></li></ol><h2 id="磁盘与模型加载" tabindex="-1">磁盘与模型加载 <a class="header-anchor" href="#磁盘与模型加载" aria-label="Permalink to “磁盘与模型加载”">​</a></h2><ol><li><strong>缓存模型</strong><br> HuggingFace 缓存目录：</li></ol><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">~</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/.cache/huggingface/hub</span></span></code></pre></div><ol start="2"><li><strong>使用 SSD 存储</strong><br> 模型加载速度远快于 HDD</li></ol><h2 id="网络优化" tabindex="-1">网络优化 <a class="header-anchor" href="#网络优化" aria-label="Permalink to “网络优化”">​</a></h2><ol><li>云服务器选择离用户最近的区域</li><li>使用 Nginx 等反向代理，启用 HTTP keep-alive</li><li>启用响应压缩（gzip）</li></ol><h2 id="常见优化场景" tabindex="-1">常见优化场景 <a class="header-anchor" href="#常见优化场景" aria-label="Permalink to “常见优化场景”">​</a></h2><ul><li><p><strong>低显存 GPU (6GB)</strong>：</p><ul><li><code>--memory-limit 0.6</code></li><li><code>dtype=&quot;float16&quot;</code></li><li>降低 API 请求中的 <code>max_tokens</code></li></ul></li><li><p><strong>高并发 API</strong>：</p><ul><li>增加 <code>uvicorn</code> workers</li><li>使用批处理</li></ul></li><li><p><strong>模型加载慢</strong>：</p><ul><li>保持服务持续运行，避免频繁重启</li><li>模型放在 SSD 上</li></ul></li></ul><h2 id="故障排查" tabindex="-1">故障排查 <a class="header-anchor" href="#故障排查" aria-label="Permalink to “故障排查”">​</a></h2><ul><li><strong>&quot;No available memory for cache blocks&quot;</strong>：降低 <code>--memory-limit</code> 或释放显存</li><li><strong>&quot;Free memory on device ... less than desired&quot;</strong>：减少显存利用率或关闭其他 GPU 进程</li><li><strong>&quot;CUDA not found&quot;</strong>：安装 NVIDIA 驱动和 CUDA 工具包</li></ul>`,25)])])}const c=s(e,[["render",n]]);export{g as __pageData,c as default};
